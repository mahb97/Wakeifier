{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTEA+NyYh+9NVJFPxuAleK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29cd02c11f2a471689e45d67c2e2fcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a9d67d94c0d4186ab0e85f226523eef",
              "IPY_MODEL_dfe6a07c93d3412b8d6e5ce35b066c8e",
              "IPY_MODEL_9df787fb5b5947759b8375ac571b8973"
            ],
            "layout": "IPY_MODEL_e5f4d3e57d844d9d8f163252d54f1134"
          }
        },
        "4a9d67d94c0d4186ab0e85f226523eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb23c32502f947d3bf4f374560ce2ce6",
            "placeholder": "​",
            "style": "IPY_MODEL_163b0700ffc642cf9c0333828934ecb3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dfe6a07c93d3412b8d6e5ce35b066c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cb16ad51ea3487abcb7fe0ab54b5da5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8af3cd2a660047b9a31b4c87924462b6",
            "value": 2
          }
        },
        "9df787fb5b5947759b8375ac571b8973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4c4fcc6e5041968615446ff8a96239",
            "placeholder": "​",
            "style": "IPY_MODEL_b5cbdefedbc04583b378db8fb60c854b",
            "value": " 2/2 [00:38&lt;00:00, 17.99s/it]"
          }
        },
        "e5f4d3e57d844d9d8f163252d54f1134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb23c32502f947d3bf4f374560ce2ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "163b0700ffc642cf9c0333828934ecb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cb16ad51ea3487abcb7fe0ab54b5da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af3cd2a660047b9a31b4c87924462b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac4c4fcc6e5041968615446ff8a96239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5cbdefedbc04583b378db8fb60c854b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61edb51cf281415c877543cab08b7ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_114e9ca6f98740b4b100bc424e054a39",
              "IPY_MODEL_50e937a3aa904afb97efc0dc581f6c8f",
              "IPY_MODEL_f0428a898d1a4a988ea9341aa1399abd"
            ],
            "layout": "IPY_MODEL_c03b2838c9ad4070a8489840d93fc7ce"
          }
        },
        "114e9ca6f98740b4b100bc424e054a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e8dd1671ea34c4da9983f04635745cd",
            "placeholder": "​",
            "style": "IPY_MODEL_d681c24a41bf49249b4a457715816fc2",
            "value": "Map: 100%"
          }
        },
        "50e937a3aa904afb97efc0dc581f6c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7236f0ef81bb4eafb51ea859425af4a5",
            "max": 1616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afa728372ac0456a96b01a2b4effd3f6",
            "value": 1616
          }
        },
        "f0428a898d1a4a988ea9341aa1399abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0713880139c14cf8a2d67f64ec55c350",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff29cd0315c46768bf45db613b71a2f",
            "value": " 1616/1616 [00:00&lt;00:00, 2761.60 examples/s]"
          }
        },
        "c03b2838c9ad4070a8489840d93fc7ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8dd1671ea34c4da9983f04635745cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d681c24a41bf49249b4a457715816fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7236f0ef81bb4eafb51ea859425af4a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa728372ac0456a96b01a2b4effd3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0713880139c14cf8a2d67f64ec55c350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff29cd0315c46768bf45db613b71a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de446584d53640aba15b01a60a19bdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6956c08da47e4b9c90f32f48f2dab9f4",
              "IPY_MODEL_8b7b711f74434864bf194cdb0c9ad1eb",
              "IPY_MODEL_4e53865a6dda43e2a6cd11fe2a360aca"
            ],
            "layout": "IPY_MODEL_b3d2412e567f4a878b3ff34ca6a47e42"
          }
        },
        "6956c08da47e4b9c90f32f48f2dab9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497d1fae5b2648dd882c6862a907a983",
            "placeholder": "​",
            "style": "IPY_MODEL_10c23fe3660c41d9bf23756e7f02d89d",
            "value": "Map: 100%"
          }
        },
        "8b7b711f74434864bf194cdb0c9ad1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8268de91adb45c3a596153128f92d34",
            "max": 1616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82682d63b3414011be873f4d69f9614f",
            "value": 1616
          }
        },
        "4e53865a6dda43e2a6cd11fe2a360aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12e4155cbd5a4b2da68a6c9bba5457e4",
            "placeholder": "​",
            "style": "IPY_MODEL_087ce5cda3614687af739b0bdd155a93",
            "value": " 1616/1616 [00:00&lt;00:00, 5077.81 examples/s]"
          }
        },
        "b3d2412e567f4a878b3ff34ca6a47e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497d1fae5b2648dd882c6862a907a983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10c23fe3660c41d9bf23756e7f02d89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8268de91adb45c3a596153128f92d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82682d63b3414011be873f4d69f9614f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12e4155cbd5a4b2da68a6c9bba5457e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087ce5cda3614687af739b0bdd155a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahb97/Wakeifier/blob/main/Wakeifyer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vevzcv4kzt4E",
        "outputId": "59a7af3e-e777-44ed-99bd-286adf01c731"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 27 20:14:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0             28W /   70W |    3702MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q \"transformers>=4.43\" \"accelerate>=0.32\" \"peft>=0.11\" \"trl>=0.9\" \"bitsandbytes>=0.43.1\" sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_wU_mfezvok",
        "outputId": "ee530d61-210d-4eff-fbf0-476ab182b9d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.8 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the model conditionally use:"
      ],
      "metadata": {
        "id": "drIeN0sSz5m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"microsoft/Phi-3-mini-4k-instruct\"  # or Mistral-7B if you have more VRAM\n",
        "\n",
        "has_cuda = torch.cuda.is_available()\n",
        "\n",
        "quant = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ") if has_cuda else None\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant,              # only active on CUDA\n",
        "    torch_dtype=torch.bfloat16 if has_cuda else torch.float32\n",
        ")\n"
      ],
      "metadata": {
        "id": "8_6u4lcmzyZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0) Setup"
      ],
      "metadata": {
        "id": "dDYM100WYGbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJaat4IyYB-o",
        "outputId": "676110dd-82e0-4456-b94d-bde14561abb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets peft accelerate trl sentencepiece bitsandbytes\n",
        "import os, textwrap, re, unicodedata, pathlib, random\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chech GPU"
      ],
      "metadata": {
        "id": "adRIIFrbx5oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os, platform\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "!nvidia-smi || echo \"No NVIDIA GPU visible\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSiqizppx39v",
        "outputId": "72af0629-9d57-425f-e9c4-08de090b8c39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Tesla T4\n",
            "Sat Sep 27 20:07:45 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Upload FW txt"
      ],
      "metadata": {
        "id": "1Q2-q5LmYS4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = Path(\"FinnegansWake.txt\").read_text(encoding=\"utf-8\")\n",
        "\n",
        "# Normalize unicode; keep Joyce’s punctuation, just tidy whitespace.\n",
        "def clean(s):\n",
        "    s = unicodedata.normalize(\"NFC\", s)\n",
        "    s = s.replace(\"\\r\\n\",\"\\n\")\n",
        "    s = re.sub(r\"[ \\t]+\",\" \", s)\n",
        "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)  # collapse huge gaps\n",
        "    return s.strip()\n",
        "\n",
        "cleaned = clean(raw)\n",
        "\n",
        "# Split into paragraphs; drop very short fragments.\n",
        "paras = [p.strip() for p in cleaned.split(\"\\n\\n\")]\n",
        "paras = [p for p in paras if len(p.split()) >= 6]\n",
        "\n",
        "print(\"Paragraphs:\", len(paras))\n",
        "Path(\"fw_paragraphs.txt\").write_text(\"\\n\\n\".join(paras), encoding=\"utf-8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acEKNjg5YqED",
        "outputId": "12643f2c-ebbf-470f-dac6-809f4ebe6d2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paragraphs: 1616\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1299781"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face dataset (packed for causal LM)"
      ],
      "metadata": {
        "id": "hX-XgwZHY2TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "ds = Dataset.from_dict({\"text\": paras})\n",
        "\n",
        "# For continued pretraining, we just use a 'text' column.\n",
        "# Pack sequences to ~1.5k tokens for efficiency.\n"
      ],
      "metadata": {
        "id": "YjAuXJMZZFD_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Small base model + LoRA config"
      ],
      "metadata": {
        "id": "S49H5xTIZVxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import torch\n",
        "\n",
        "BASE = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(BASE, use_fast=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "# 4-bit quantization (CUDA only)\n",
        "bnb_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_cfg,\n",
        ")\n",
        "\n",
        "# ✨ critical bits for QLoRA:\n",
        "model.config.use_cache = False                           # needed with grad checkpointing\n",
        "model = prepare_model_for_kbit_training(model)           # enables input grads, fixes norms\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16, lora_alpha=16, lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "model.print_trainable_parameters()  # sanity check: LoRA params should be trainable\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "29cd02c11f2a471689e45d67c2e2fcbe",
            "4a9d67d94c0d4186ab0e85f226523eef",
            "dfe6a07c93d3412b8d6e5ce35b066c8e",
            "9df787fb5b5947759b8375ac571b8973",
            "e5f4d3e57d844d9d8f163252d54f1134",
            "cb23c32502f947d3bf4f374560ce2ce6",
            "163b0700ffc642cf9c0333828934ecb3",
            "1cb16ad51ea3487abcb7fe0ab54b5da5",
            "8af3cd2a660047b9a31b4c87924462b6",
            "ac4c4fcc6e5041968615446ff8a96239",
            "b5cbdefedbc04583b378db8fb60c854b"
          ]
        },
        "id": "XTStvqmM2orQ",
        "outputId": "aec8dd68-668e-4d74-9d1f-f2e8b5637965"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29cd02c11f2a471689e45d67c2e2fcbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,145,728 || all params: 3,824,225,280 || trainable%: 0.0823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"wake_lora_dapt\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    warmup_ratio=0.05,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,                       # multiple of eval_steps\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    bf16=True,\n",
        "    gradient_checkpointing=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    report_to=\"none\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "mlzLcOAu4jLL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize + pack (no labels column needed; next-token loss)"
      ],
      "metadata": {
        "id": "YEwOCAVFZrmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "max_len = 1536\n",
        "\n",
        "def tokenize(examples):\n",
        "    return tok(examples[\"text\"], truncation=False)\n",
        "\n",
        "tokenized = ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# Pack into fixed-length blocks for causal LM (concatenate then chunk)\n",
        "def group_texts(examples):\n",
        "    concat = []\n",
        "    for ids in examples[\"input_ids\"]:\n",
        "        concat.extend(ids + [tok.eos_token_id])\n",
        "    # chunk\n",
        "    result = {\"input_ids\": [], \"attention_mask\": []}\n",
        "    for i in range(0, len(concat), max_len):\n",
        "        chunk = concat[i:i+max_len]\n",
        "        if len(chunk) == max_len:\n",
        "            result[\"input_ids\"].append(chunk)\n",
        "            result[\"attention_mask\"].append([1]*max_len)\n",
        "    return result\n",
        "\n",
        "lm_ds = tokenized.map(group_texts, batched=True)\n",
        "\n",
        "# Tiny train/valid split\n",
        "lm_ds = lm_ds.train_test_split(test_size=0.02, seed=42)\n",
        "train_ds, val_ds = lm_ds[\"train\"], lm_ds[\"test\"]\n",
        "\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tok, mlm=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "61edb51cf281415c877543cab08b7ad6",
            "114e9ca6f98740b4b100bc424e054a39",
            "50e937a3aa904afb97efc0dc581f6c8f",
            "f0428a898d1a4a988ea9341aa1399abd",
            "c03b2838c9ad4070a8489840d93fc7ce",
            "4e8dd1671ea34c4da9983f04635745cd",
            "d681c24a41bf49249b4a457715816fc2",
            "7236f0ef81bb4eafb51ea859425af4a5",
            "afa728372ac0456a96b01a2b4effd3f6",
            "0713880139c14cf8a2d67f64ec55c350",
            "9ff29cd0315c46768bf45db613b71a2f",
            "de446584d53640aba15b01a60a19bdd2",
            "6956c08da47e4b9c90f32f48f2dab9f4",
            "8b7b711f74434864bf194cdb0c9ad1eb",
            "4e53865a6dda43e2a6cd11fe2a360aca",
            "b3d2412e567f4a878b3ff34ca6a47e42",
            "497d1fae5b2648dd882c6862a907a983",
            "10c23fe3660c41d9bf23756e7f02d89d",
            "f8268de91adb45c3a596153128f92d34",
            "82682d63b3414011be873f4d69f9614f",
            "12e4155cbd5a4b2da68a6c9bba5457e4",
            "087ce5cda3614687af739b0bdd155a93"
          ]
        },
        "id": "LPR8KWcNZud4",
        "outputId": "31e6ace8-6653-4708-babf-0f2220a8c586"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1616 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61edb51cf281415c877543cab08b7ad6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1616 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de446584d53640aba15b01a60a19bdd2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train (continued pretraining with LoRA)"
      ],
      "metadata": {
        "id": "ZCHQF3CS0Oud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "smoke run"
      ],
      "metadata": {
        "id": "uE-FqGP8_VOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"wake_lora_dapt_smoke\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=1,   # fast feedback\n",
        "    max_steps=40,                    # stop quickly\n",
        "    learning_rate=2e-4,\n",
        "    warmup_ratio=0.05,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=1,                 # ← print every step\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"no\",\n",
        "    bf16=torch.cuda.is_available(),\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"none\",\n",
        "    dataloader_num_workers=0,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds.select(range(min(512, len(train_ds)))),  # small slice\n",
        "    data_collator=collator,\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "I53fg5Gs_Y41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LoRA gives model a Finnegans-Wake “bias” without needing to retrain the whole network & it runs on a free Colab GPU."
      ],
      "metadata": {
        "id": "oFXWewzs_3n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "out_dir = \"wake_lora_dapt\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=out_dir,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=16,     # effective batch ~32\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    warmup_ratio=0.05,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=250,                      # multiple of 500 below\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,                      # 2 × 250\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    bf16=torch.cuda.is_available(),\n",
        "    gradient_checkpointing=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    data_collator=collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "print(trainer.evaluate())\n",
        "trainer.save_model(out_dir)\n",
        "tok.save_pretrained(out_dir)\n",
        "print(\"Saved to\", out_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "d078qnru2Fme",
        "outputId": "89b90b94-89d8-4083-8126-13c83a40640f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 2:33:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 4.8898444175720215, 'eval_runtime': 33.7101, 'eval_samples_per_second': 0.178, 'eval_steps_per_second': 0.089, 'epoch': 2.0}\n",
            "Saved to wake_lora_dapt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity Check"
      ],
      "metadata": {
        "id": "ijcJWcYUAKZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, math\n",
        "print(\"CUDA:\", torch.cuda.is_available())\n",
        "print(\"Train chunks:\", len(train_ds), \"| Val chunks:\", len(val_ds))\n",
        "\n",
        "per_device = 2\n",
        "grad_acc = 16\n",
        "gpus = torch.cuda.device_count() or 1\n",
        "eff_batch = per_device * grad_acc * gpus\n",
        "steps_per_epoch = math.ceil(len(train_ds) / eff_batch)\n",
        "print(\"Effective batch:\", eff_batch, \"| Estimated steps/epoch:\", steps_per_epoch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deE0fJrF5EVZ",
        "outputId": "ef4e7232-e79a-4308-f55d-683b66432a75"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: True\n",
            "Train chunks: 266 | Val chunks: 6\n",
            "Effective batch: 32 | Estimated steps/epoch: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Final eval (optional)\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)\n",
        "\n",
        "# 2) Save adapter + tokenizer\n",
        "trainer.save_model(\"wake_lora_dapt\")\n",
        "tok.save_pretrained(\"wake_lora_dapt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "6fjwks3DRFSZ",
        "outputId": "ed3901e2-dbbc-4ba6-e2b9-bb603f3c3340"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 02:19]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 4.8898444175720215, 'eval_runtime': 35.5393, 'eval_samples_per_second': 0.169, 'eval_steps_per_second': 0.084, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('wake_lora_dapt/tokenizer_config.json',\n",
              " 'wake_lora_dapt/special_tokens_map.json',\n",
              " 'wake_lora_dapt/chat_template.jinja',\n",
              " 'wake_lora_dapt/tokenizer.model',\n",
              " 'wake_lora_dapt/added_tokens.json',\n",
              " 'wake_lora_dapt/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick test generation (uses the model already in memory)"
      ],
      "metadata": {
        "id": "e6C1A1KLRNSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wake_generate(prompt, max_new_tokens=160, temperature=1.0, top_p=0.95, rep_pen=1.1):\n",
        "    sys = \"You write in a Finnegans Wake-like style while preserving the factual content of the prompt.\"\n",
        "    chat = f\"<|system|>\\n{sys}\\n<|user|>\\n{prompt}\\n<|assistant|>\\n\"\n",
        "    inputs = tok(chat, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs, do_sample=True, temperature=temperature, top_p=top_p,\n",
        "            repetition_penalty=rep_pen, max_new_tokens=max_new_tokens,\n",
        "            pad_token_id=tok.eos_token_id\n",
        "        )\n",
        "    return tok.decode(out_ids[0], skip_special_tokens=True).split(\"<|assistant|>\")[-1].strip()\n",
        "\n",
        "print(wake_generate(\"Please confirm receipt of the attached report by Friday.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw1E2Ya_RObT",
        "outputId": "d7acaf8c-c9c5-41be-fa02-3abda6b90257"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You write in a Finnegans Wake-like style while preserving the factual content of the prompt.\n",
            " Please confirm receipt of the attached report by Friday.\n",
            " Absolutely, like pears on Pearson's platter, post haste peruse shall be performed; punctiliously as Prometheus propounds prior to peering profoundly at penumbra parables provided for personal parsing—proliferated proofs pressed upon porcelain promised before Peary’s Pendulous period poised precipitating procession purveyed particularized providence precluding perturbation or pause. Perforce pending passage past Paladin Ploughman, present pertinence proclaiming peerlessness perpetuates prudential participation with peculiarity pushed persistently towards pronounced professionals permitted proper perfunctory protocol precedence permissible public presentation plus placid passivity paired perfectly providing palpable product\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to reload later (base + LoRA adapter)"
      ],
      "metadata": {
        "id": "YhDC-ihbRV8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "BASE = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(BASE, use_fast=True)\n",
        "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE, device_map=\"auto\", torch_dtype=torch.bfloat16\n",
        ")\n",
        "model = PeftModel.from_pretrained(base, \"wake_lora_dapt\")  # your saved adapter folder\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "8UDgtgH7RQkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "permanently merge adapter into the base for export"
      ],
      "metadata": {
        "id": "vabXHQNDRZrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged = model.merge_and_unload()  # may use more VRAM; skip if you stay with PEFT\n"
      ],
      "metadata": {
        "id": "c5hyLdn0RZcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save - Zip & download"
      ],
      "metadata": {
        "id": "kYq0fHsjRiDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r wake_lora_dapt.zip wake_lora_dapt\n",
        "from google.colab import files; files.download(\"wake_lora_dapt.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "a7wG-ykiRfWl",
        "outputId": "bcf4edbd-b981-43d0-9285-3592e8a99168"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: wake_lora_dapt/ (stored 0%)\n",
            "  adding: wake_lora_dapt/chat_template.jinja (deflated 60%)\n",
            "  adding: wake_lora_dapt/adapter_model.safetensors (deflated 9%)\n",
            "  adding: wake_lora_dapt/adapter_config.json (deflated 56%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/ (stored 0%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/chat_template.jinja (deflated 60%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/scheduler.pt (deflated 62%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/trainer_state.json (deflated 56%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/adapter_model.safetensors (deflated 9%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/adapter_config.json (deflated 56%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/special_tokens_map.json (deflated 79%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/rng_state.pth (deflated 26%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/tokenizer.model (deflated 55%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/tokenizer.json (deflated 85%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/added_tokens.json (deflated 62%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/README.md (deflated 65%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/tokenizer_config.json (deflated 86%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/optimizer.pt (deflated 8%)\n",
            "  adding: wake_lora_dapt/checkpoint-18/training_args.bin (deflated 54%)\n",
            "  adding: wake_lora_dapt/special_tokens_map.json (deflated 79%)\n",
            "  adding: wake_lora_dapt/tokenizer.model (deflated 55%)\n",
            "  adding: wake_lora_dapt/tokenizer.json (deflated 85%)\n",
            "  adding: wake_lora_dapt/added_tokens.json (deflated 62%)\n",
            "  adding: wake_lora_dapt/README.md (deflated 65%)\n",
            "  adding: wake_lora_dapt/tokenizer_config.json (deflated 86%)\n",
            "  adding: wake_lora_dapt/training_args.bin (deflated 54%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f45e8fd8-68fa-4b81-a12b-e456583f5355\", \"wake_lora_dapt.zip\", 47800429)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or copy to drive"
      ],
      "metadata": {
        "id": "3KqKvDuYRm2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive; drive.mount(\"/content/drive\")\n",
        "!cp -r wake_lora_dapt /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "zI3Bm6ZuRom8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Real trining pass (epoch-based = fewer hiccups)"
      ],
      "metadata": {
        "id": "xrqQykXP6ca5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"wake_lora_dapt\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=16,   # effective batch ~= 32\n",
        "    num_train_epochs=2,               # 2; can bump to 3 later\n",
        "    learning_rate=2e-4,\n",
        "    warmup_ratio=0.05,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    bf16=torch.cuda.is_available(),\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"none\",\n",
        "    dataloader_num_workers=0\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                 # QLoRA-prepared model from earlier\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    data_collator=collator\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "print(trainer.evaluate())\n",
        "trainer.save_model(\"wake_lora_dapt\")\n",
        "tok.save_pretrained(\"wake_lora_dapt\")"
      ],
      "metadata": {
        "id": "vOMwlteB6pu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "quick generation helper"
      ],
      "metadata": {
        "id": "VHzz-wZ26wH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def wake_generate(prompt, max_new_tokens=180, temperature=1.1, top_p=0.95, rep_pen=1.1):\n",
        "    sys = \"You write in a Finnegans Wake-like style while preserving the factual content of the prompt.\"\n",
        "    chat = f\"<|system|>\\n{sys}\\n<|user|>\\n{prompt}\\n<|assistant|>\\n\"\n",
        "    inputs = tok(chat, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=True,\n",
        "            temperature=temperature, top_p=top_p,\n",
        "            repetition_penalty=rep_pen,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            pad_token_id=tok.eos_token_id,\n",
        "        )\n",
        "    return tok.decode(out_ids[0], skip_special_tokens=True).split(\"<|assistant|>\")[-1].strip()\n",
        "\n",
        "print(wake_generate(\"The man is walking to the shop to buy some milk.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY2R5TNj6xQv",
        "outputId": "5253d215-7d89-40ef-be28-e4f3d04fca0c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You write in a Finnegans Wake-like style while preserving the factual content of the prompt.\n",
            " The man is walking to the shop to buy some milk.\n",
            " Ah, there goes our protagonist on his humble daily sojourn for lactum potable's replenishment; an odyssey quite mundane yet indispensably quixotic! Each step taken by this lonesome individual bespeaks tales untold – from chores and sustenance pursuits drenched deeply with life’s ephemeral complexities—as he embarks toward Dairyland extravaganza. His mission: procure a pint that not only satiates pallid hunger within but weaves together moments shared across countless smiles exchanged over breakfast tables amidst familial merriment or solitary silences during nocturnal introspection alike - all tied subtly unto itself as one delves beyond its apparent simplistic superficiality into existential expl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  Too tame? ↑ temperature to 1.1.\n",
        "*  Too wild / off-topic? ↓ temperature to 0.8 and ↑ repetition_penalty to 1.15.\n"
      ],
      "metadata": {
        "id": "jsAuHtdw94n6"
      }
    }
  ]
}